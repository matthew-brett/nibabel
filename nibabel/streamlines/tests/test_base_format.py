import os
import unittest
import numpy as np
import warnings

from nibabel.testing import assert_arrays_equal
from nibabel.testing import suppress_warnings, clear_and_catch_warnings
from nose.tools import assert_equal, assert_raises, assert_true
from numpy.testing import assert_array_equal, assert_array_almost_equal
from nibabel.externals.six.moves import zip, zip_longest

from .. import base_format
from ..base_format import CompactList
from ..base_format import TractogramItem, Tractogram, LazyTractogram
from ..base_format import UsageWarning

DATA_PATH = os.path.join(os.path.dirname(__file__), 'data')


class TestCompactList(unittest.TestCase):

    def setUp(self):
        rng = np.random.RandomState(42)
        self.data = [rng.rand(rng.randint(10, 50), 3) for _ in range(10)]
        self.lengths = map(len, self.data)
        self.clist = CompactList(self.data)

    def test_creating_empty_compactlist(self):
        clist = CompactList()
        assert_equal(len(clist), 0)
        assert_equal(len(clist._offsets), 0)
        assert_equal(len(clist._lengths), 0)
        assert_true(clist._data is None)
        assert_true(clist.shape is None)

    def test_creating_compactlist_from_list(self):
        rng = np.random.RandomState(42)
        data = [rng.rand(rng.randint(10, 50), 3) for _ in range(10)]
        lengths = map(len, data)

        clist = CompactList(data)
        assert_equal(len(clist), len(data))
        assert_equal(len(clist._offsets), len(data))
        assert_equal(len(clist._lengths), len(data))
        assert_equal(clist._data.shape[0], sum(lengths))
        assert_equal(clist._data.shape[1], 3)
        assert_equal(clist._offsets, [0] + np.cumsum(lengths)[:-1].tolist())
        assert_equal(clist._lengths, lengths)
        assert_equal(clist.shape, data[0].shape[1:])

        # Empty list
        clist = CompactList([])
        assert_equal(len(clist), 0)
        assert_equal(len(clist._offsets), 0)
        assert_equal(len(clist._lengths), 0)
        assert_true(clist._data is None)
        assert_true(clist.shape is None)

    def test_creating_compactlist_from_generator(self):
        rng = np.random.RandomState(42)
        data = [rng.rand(rng.randint(10, 50), 3) for _ in range(10)]
        lengths = map(len, data)

        gen = (e for e in data)
        clist = CompactList(gen)
        assert_equal(len(clist), len(data))
        assert_equal(len(clist._offsets), len(data))
        assert_equal(len(clist._lengths), len(data))
        assert_equal(clist._data.shape[0], sum(lengths))
        assert_equal(clist._data.shape[1], 3)
        assert_equal(clist._offsets, [0] + np.cumsum(lengths)[:-1].tolist())
        assert_equal(clist._lengths, lengths)
        assert_equal(clist.shape, data[0].shape[1:])

        # Already consumed generator
        clist = CompactList(gen)
        assert_equal(len(clist), 0)
        assert_equal(len(clist._offsets), 0)
        assert_equal(len(clist._lengths), 0)
        assert_true(clist._data is None)
        assert_true(clist.shape is None)

    def test_creating_compactlist_from_compact_list(self):
        rng = np.random.RandomState(42)
        data = [rng.rand(rng.randint(10, 50), 3) for _ in range(10)]
        lengths = map(len, data)

        clist = CompactList(data)
        clist2 = CompactList(clist)
        assert_equal(len(clist2), len(data))
        assert_equal(len(clist2._offsets), len(data))
        assert_equal(len(clist2._lengths), len(data))
        assert_equal(clist2._data.shape[0], sum(lengths))
        assert_equal(clist2._data.shape[1], 3)
        assert_equal(clist2._offsets, [0] + np.cumsum(lengths)[:-1].tolist())
        assert_equal(clist2._lengths, lengths)
        assert_equal(clist2.shape, data[0].shape[1:])

    def test_compactlist_iter(self):
        for e, d in zip(self.clist, self.data):
            assert_array_equal(e, d)

    def test_compactlist_copy(self):
        clist = self.clist.copy()
        assert_array_equal(clist._data, self.clist._data)
        assert_true(clist._data is not self.clist._data)
        assert_array_equal(clist._offsets, self.clist._offsets)
        assert_true(clist._offsets is not self.clist._offsets)
        assert_array_equal(clist._lengths, self.clist._lengths)
        assert_true(clist._lengths is not self.clist._lengths)

        assert_equal(clist.shape, self.clist.shape)

        # When taking a copy of a `CompactList` generated by slicing.
        # Only needed data should be kept.
        clist = self.clist[::2].copy()

        assert_true(clist._data.shape[0] < self.clist._data.shape[0])
        assert_true(len(clist) < len(self.clist))
        assert_true(clist._data is not self.clist._data)

    def test_compactlist_append(self):
        # Maybe not necessary if `self.setUp` is always called before a
        # test method, anyways create a copy just in case.
        clist = self.clist.copy()

        rng = np.random.RandomState(1234)
        element = rng.rand(rng.randint(10, 50), *self.clist.shape)
        clist.append(element)
        assert_equal(len(clist), len(self.clist)+1)
        assert_equal(clist._offsets[-1], len(self.clist._data))
        assert_equal(clist._lengths[-1], len(element))
        assert_array_equal(clist._data[-len(element):], element)

        # Append with different shape.
        element = rng.rand(rng.randint(10, 50), 42)
        assert_raises(ValueError, clist.append, element)

        # Append to an empty CompactList.
        clist = CompactList()
        rng = np.random.RandomState(1234)
        shape = (2, 3, 4)
        element = rng.rand(rng.randint(10, 50), *shape)
        clist.append(element)

        assert_equal(len(clist), 1)
        assert_equal(clist._offsets[-1], 0)
        assert_equal(clist._lengths[-1], len(element))
        assert_array_equal(clist._data, element)
        assert_equal(clist.shape, shape)

    def test_compactlist_extend(self):
        # Maybe not necessary if `self.setUp` is always called before a
        # test method, anyways create a copy just in case.
        clist = self.clist.copy()

        rng = np.random.RandomState(1234)
        shape = self.clist.shape
        new_data = [rng.rand(rng.randint(10, 50), *shape) for _ in range(5)]
        lengths = map(len, new_data)
        clist.extend(new_data)
        assert_equal(len(clist), len(self.clist)+len(new_data))
        assert_array_equal(clist._offsets[-len(new_data):],
                           len(self.clist._data) + np.cumsum([0] + lengths[:-1]))

        assert_equal(clist._lengths[-len(new_data):], lengths)
        assert_array_equal(clist._data[-sum(lengths):],
                           np.concatenate(new_data, axis=0))

        # Extend with another `CompactList` object.
        clist = self.clist.copy()
        new_data = CompactList(new_data)
        clist.extend(new_data)
        assert_equal(len(clist), len(self.clist)+len(new_data))
        assert_array_equal(clist._offsets[-len(new_data):],
                           len(self.clist._data) + np.cumsum([0] + lengths[:-1]))

        assert_equal(clist._lengths[-len(new_data):], lengths)
        assert_array_equal(clist._data[-sum(lengths):], new_data._data)

    def test_compactlist_getitem(self):
        # Get one item
        for i, e in enumerate(self.clist):
            assert_array_equal(self.clist[i], e)

        # Get multiple items (this will create a view).
        clist_view = self.clist[range(len(self.clist))]
        assert_true(clist_view is not self.clist)
        assert_true(clist_view._data is self.clist._data)
        assert_true(clist_view._offsets is not self.clist._offsets)
        assert_true(clist_view._lengths is not self.clist._lengths)
        assert_array_equal(clist_view._offsets, self.clist._offsets)
        assert_array_equal(clist_view._lengths, self.clist._lengths)
        for e1, e2 in zip_longest(clist_view, self.clist):
            assert_array_equal(e1, e2)

        # Get slice (this will create a view).
        clist_view = self.clist[::2]
        assert_true(clist_view is not self.clist)
        assert_true(clist_view._data is self.clist._data)
        assert_array_equal(clist_view._offsets, self.clist._offsets[::2])
        assert_array_equal(clist_view._lengths, self.clist._lengths[::2])
        for i, e in enumerate(clist_view):
            assert_array_equal(e, self.clist[i*2])


class TestTractogramItem(unittest.TestCase):

    def test_creating_tractogram_item(self):
        rng = np.random.RandomState(42)
        points = rng.rand(rng.randint(10, 50), 3)
        scalars = rng.rand(len(points), 5)
        properties = rng.rand(42)

        # Create a streamline with only points
        s = TractogramItem(points)
        assert_equal(len(s), len(points))
        assert_array_equal(s.scalars, [])
        assert_array_equal(s.properties, [])

        # Create a streamline with points, scalars and properties.
        s = TractogramItem(points, scalars, properties)
        assert_equal(len(s), len(points))
        assert_array_equal(s.points, points)
        assert_array_equal(list(s), points)
        assert_equal(len(s), len(scalars))
        assert_array_equal(s.scalars, scalars)
        assert_array_equal(s.properties, properties)

        # # Create a streamline with different number of scalars.
        # scalars = rng.rand(len(points)+3, 5)
        # assert_raises(ValueError, TractogramItem, points, scalars)


class TestTractogram(unittest.TestCase):

    def setUp(self):
        self.empty_trk_filename = os.path.join(DATA_PATH, "empty.trk")
        self.simple_trk_filename = os.path.join(DATA_PATH, "simple.trk")
        self.complex_trk_filename = os.path.join(DATA_PATH, "complex.trk")

        self.points = [np.arange(1*3, dtype="f4").reshape((1, 3)),
                       np.arange(2*3, dtype="f4").reshape((2, 3)),
                       np.arange(5*3, dtype="f4").reshape((5, 3))]

        self.colors = [np.array([(1, 0, 0)]*1, dtype="f4"),
                       np.array([(0, 1, 0)]*2, dtype="f4"),
                       np.array([(0, 0, 1)]*5, dtype="f4")]

        self.mean_curvature_torsion = [np.array([1.11, 1.22], dtype="f4"),
                                       np.array([2.11, 2.22], dtype="f4"),
                                       np.array([3.11, 3.22], dtype="f4")]

        self.nb_streamlines = len(self.points)
        self.nb_scalars_per_point = self.colors[0].shape[1]
        self.nb_properties_per_streamline = len(self.mean_curvature_torsion[0])

    def test_streamlines_creation_from_arrays(self):
        # Empty
        streamlines = Tractogram()
        assert_equal(len(streamlines), 0)
        assert_arrays_equal(streamlines.points, [])
        assert_arrays_equal(streamlines.scalars, [])
        assert_arrays_equal(streamlines.properties, [])

        # Check if we can iterate through the streamlines.
        for streamline in streamlines:
            pass

        # Only points
        streamlines = Tractogram(points=self.points)
        assert_equal(len(streamlines), len(self.points))
        assert_arrays_equal(streamlines.points, self.points)
        assert_arrays_equal(streamlines.scalars, [])
        assert_arrays_equal(streamlines.properties, [])

        # Check if we can iterate through the streamlines.
        for streamline in streamlines:
            pass

        # Points, scalars and properties
        streamlines = Tractogram(self.points, self.colors, self.mean_curvature_torsion)
        assert_equal(len(streamlines), len(self.points))
        assert_arrays_equal(streamlines.points, self.points)
        assert_arrays_equal(streamlines.scalars, self.colors)
        assert_arrays_equal(streamlines.properties, self.mean_curvature_torsion)

        # Check if we can iterate through the streamlines.
        for streamline in streamlines:
            pass

        # Inconsistent number of scalars between points
        scalars = [[(1, 0, 0)]*1,
                   [(0, 1, 0), (0, 1)],
                   [(0, 0, 1)]*5]

        assert_raises(ValueError, Tractogram, self.points, scalars)

        # Unit test moved to test_base_format.py
        # Inconsistent number of scalars between streamlines
        scalars = [[(1, 0, 0)]*1,
                   [(0, 1)]*2,
                   [(0, 0, 1)]*5]

        assert_raises(ValueError, Tractogram, self.points, scalars)

    def test_streamlines_getter(self):
        # Tractogram with only points
        streamlines = Tractogram(points=self.points)

        selected_streamlines = streamlines[::2]
        assert_equal(len(selected_streamlines), (len(self.points)+1)//2)

        assert_arrays_equal(selected_streamlines.points, self.points[::2])
        assert_equal(sum(map(len, selected_streamlines.scalars)), 0)
        assert_equal(sum(map(len, selected_streamlines.properties)), 0)

        # Tractogram with points, scalars and properties
        streamlines = Tractogram(self.points, self.colors, self.mean_curvature_torsion)

        # Retrieve streamlines by their index
        for i, streamline in enumerate(streamlines):
            assert_array_equal(streamline.points, streamlines[i].points)
            assert_array_equal(streamline.scalars, streamlines[i].scalars)
            assert_array_equal(streamline.properties, streamlines[i].properties)

        # Use slicing
        r_streamlines = streamlines[::-1]
        assert_arrays_equal(r_streamlines.points, self.points[::-1])
        assert_arrays_equal(r_streamlines.scalars, self.colors[::-1])
        assert_arrays_equal(r_streamlines.properties, self.mean_curvature_torsion[::-1])

    def test_streamlines_creation_from_coroutines(self):
        # Points, scalars and properties
        points = lambda: (x for x in self.points)
        scalars = lambda: (x for x in self.colors)
        properties = lambda: (x for x in self.mean_curvature_torsion)

        # To create streamlines from coroutines use `LazyTractogram`.
        assert_raises(TypeError, Tractogram, points, scalars, properties)

    def test_header(self):
        # Empty Tractogram, with default header
        streamlines = Tractogram()
        assert_equal(streamlines.header.nb_streamlines, 0)
        assert_equal(streamlines.header.nb_scalars_per_point, 0)
        assert_equal(streamlines.header.nb_properties_per_streamline, 0)
        assert_array_equal(streamlines.header.voxel_sizes, (1, 1, 1))
        assert_array_equal(streamlines.header.to_world_space, np.eye(4))
        assert_equal(streamlines.header.extra, {})

        streamlines = Tractogram(self.points, self.colors, self.mean_curvature_torsion)

        assert_equal(streamlines.header.nb_streamlines, len(self.points))
        assert_equal(streamlines.header.nb_scalars_per_point, self.colors[0].shape[1])
        assert_equal(streamlines.header.nb_properties_per_streamline, self.mean_curvature_torsion[0].shape[0])

        # Modifying voxel_sizes should be reflected in to_world_space
        streamlines.header.voxel_sizes = (2, 3, 4)
        assert_array_equal(streamlines.header.voxel_sizes, (2, 3, 4))
        assert_array_equal(np.diag(streamlines.header.to_world_space), (2, 3, 4, 1))

        # Modifying scaling of to_world_space should be reflected in voxel_sizes
        streamlines.header.to_world_space = np.diag([4, 3, 2, 1])
        assert_array_equal(streamlines.header.voxel_sizes, (4, 3, 2))
        assert_array_equal(streamlines.header.to_world_space, np.diag([4, 3, 2, 1]))

        # Test that we can run __repr__ without error.
        repr(streamlines.header)



class TestLazyTractogram(unittest.TestCase):

    def setUp(self):
        self.empty_trk_filename = os.path.join(DATA_PATH, "empty.trk")
        self.simple_trk_filename = os.path.join(DATA_PATH, "simple.trk")
        self.complex_trk_filename = os.path.join(DATA_PATH, "complex.trk")

        self.points = [np.arange(1*3, dtype="f4").reshape((1, 3)),
                       np.arange(2*3, dtype="f4").reshape((2, 3)),
                       np.arange(5*3, dtype="f4").reshape((5, 3))]

        self.colors = [np.array([(1, 0, 0)]*1, dtype="f4"),
                       np.array([(0, 1, 0)]*2, dtype="f4"),
                       np.array([(0, 0, 1)]*5, dtype="f4")]

        self.mean_curvature_torsion = [np.array([1.11, 1.22], dtype="f4"),
                                       np.array([2.11, 2.22], dtype="f4"),
                                       np.array([3.11, 3.22], dtype="f4")]

        self.nb_streamlines = len(self.points)
        self.nb_scalars_per_point = self.colors[0].shape[1]
        self.nb_properties_per_streamline = len(self.mean_curvature_torsion[0])

    def test_lazy_streamlines_creation(self):
        # To create streamlines from arrays use `Tractogram`.
        assert_raises(TypeError, LazyTractogram, self.points)

        # Points, scalars and properties
        points = (x for x in self.points)
        scalars = (x for x in self.colors)
        properties = (x for x in self.mean_curvature_torsion)

        # Creating LazyTractogram from generators is not allowed as
        # generators get exhausted and are not reusable unline coroutines.
        assert_raises(TypeError, LazyTractogram, points)
        assert_raises(TypeError, LazyTractogram, self.points, scalars)
        assert_raises(TypeError, LazyTractogram, properties_func=properties)

        # Empty `LazyTractogram`
        streamlines = LazyTractogram()
        with suppress_warnings():
            assert_equal(len(streamlines), 0)
        assert_arrays_equal(streamlines.points, [])
        assert_arrays_equal(streamlines.scalars, [])
        assert_arrays_equal(streamlines.properties, [])

        # Check if we can iterate through the streamlines.
        for streamline in streamlines:
            pass

        # Points, scalars and properties
        points = lambda: (x for x in self.points)
        scalars = lambda: (x for x in self.colors)
        properties = lambda: (x for x in self.mean_curvature_torsion)

        streamlines = LazyTractogram(points, scalars, properties)
        with suppress_warnings():
            assert_equal(len(streamlines), self.nb_streamlines)

        # Coroutines get re-called and creates new iterators.
        assert_arrays_equal(streamlines.points, self.points)
        assert_arrays_equal(streamlines.scalars, self.colors)
        assert_arrays_equal(streamlines.properties, self.mean_curvature_torsion)
        assert_arrays_equal(streamlines.points, self.points)
        assert_arrays_equal(streamlines.scalars, self.colors)
        assert_arrays_equal(streamlines.properties, self.mean_curvature_torsion)

        # Create `LazyTractogram` from a coroutine yielding 3-tuples
        data = lambda: (x for x in zip(self.points, self.colors, self.mean_curvature_torsion))

        streamlines = LazyTractogram.create_from_data(data)
        with suppress_warnings():
            assert_equal(len(streamlines), self.nb_streamlines)
        assert_arrays_equal(streamlines.points, self.points)
        assert_arrays_equal(streamlines.scalars, self.colors)
        assert_arrays_equal(streamlines.properties, self.mean_curvature_torsion)

        # Check if we can iterate through the streamlines.
        for streamline in streamlines:
            pass

    def test_lazy_streamlines_indexing(self):
        points = lambda: (x for x in self.points)
        scalars = lambda: (x for x in self.colors)
        properties = lambda: (x for x in self.mean_curvature_torsion)

        # By default, `LazyTractogram` object does not support indexing.
        streamlines = LazyTractogram(points, scalars, properties)
        assert_raises(AttributeError, streamlines.__getitem__, 0)

        # Create a `LazyTractogram` object with indexing support.
        def getitem_without_properties(idx):
            if isinstance(idx, int) or isinstance(idx, np.integer):
                return self.points[idx], self.colors[idx]

            return list(zip(self.points[idx], self.colors[idx]))

        streamlines = LazyTractogram(points, scalars, properties, getitem_without_properties)
        points, scalars = streamlines[0]
        assert_array_equal(points, self.points[0])
        assert_array_equal(scalars, self.colors[0])

        points, scalars = zip(*streamlines[::-1])
        assert_arrays_equal(points, self.points[::-1])
        assert_arrays_equal(scalars, self.colors[::-1])

        points, scalars = zip(*streamlines[:-1])
        assert_arrays_equal(points, self.points[:-1])
        assert_arrays_equal(scalars, self.colors[:-1])

    def test_lazy_streamlines_len(self):
        points = lambda: (x for x in self.points)
        scalars = lambda: (x for x in self.colors)
        properties = lambda: (x for x in self.mean_curvature_torsion)

        with clear_and_catch_warnings(record=True, modules=[base_format]) as w:
            warnings.simplefilter("always")  # Always trigger warnings.

            # Calling `len` will create new generators each time.
            streamlines = LazyTractogram(points, scalars, properties)
            # This should produce a warning message.
            assert_equal(len(streamlines), self.nb_streamlines)
            assert_equal(len(w), 1)

            streamlines = LazyTractogram(points, scalars, properties)
            # This should still produce a warning message.
            assert_equal(len(streamlines), self.nb_streamlines)
            assert_equal(len(w), 2)
            assert_true(issubclass(w[-1].category, UsageWarning))

            # This should *not* produce a warning.
            assert_equal(len(streamlines), self.nb_streamlines)
            assert_equal(len(w), 2)

        with clear_and_catch_warnings(record=True, modules=[base_format]) as w:
            # Once we iterated through the streamlines, we know the length.
            streamlines = LazyTractogram(points, scalars, properties)
            assert_true(streamlines.header.nb_streamlines is None)
            for streamline in streamlines:
                pass

            assert_equal(streamlines.header.nb_streamlines, len(self.points))
            # This should *not* produce a warning.
            assert_equal(len(streamlines), len(self.points))
            assert_equal(len(w), 0)

        with clear_and_catch_warnings(record=True, modules=[base_format]) as w:
            # It first checks if number of streamlines is in the header.
            streamlines = LazyTractogram(points, scalars, properties)
            streamlines.header.nb_streamlines = 1234
            # This should *not* produce a warning.
            assert_equal(len(streamlines), 1234)
            assert_equal(len(w), 0)

    def test_lazy_streamlines_header(self):
        # Empty `LazyTractogram`, with default header
        streamlines = LazyTractogram()
        assert_true(streamlines.header.nb_streamlines is None)
        assert_equal(streamlines.header.nb_scalars_per_point, 0)
        assert_equal(streamlines.header.nb_properties_per_streamline, 0)
        assert_array_equal(streamlines.header.voxel_sizes, (1, 1, 1))
        assert_array_equal(streamlines.header.to_world_space, np.eye(4))
        assert_equal(streamlines.header.extra, {})

        points = lambda: (x for x in self.points)
        scalars = lambda: (x for x in self.colors)
        properties = lambda: (x for x in self.mean_curvature_torsion)
        streamlines = LazyTractogram(points)
        header = streamlines.header

        assert_equal(header.nb_scalars_per_point, 0)
        streamlines.scalars = scalars
        assert_equal(header.nb_scalars_per_point, self.nb_scalars_per_point)

        assert_equal(header.nb_properties_per_streamline, 0)
        streamlines.properties = properties
        assert_equal(header.nb_properties_per_streamline, self.nb_properties_per_streamline)
